import re
import logging
from pathlib import Path
from typing import List, Tuple
from tqdm import tqdm
from config import DEBUG_CLEAN_DIR

# ========== å·¥å…·å‡½æ•° ==========
def extract_code_blocks(text: str) -> Tuple[str, List[str]]:
    code_blocks = []
    def replacer(match):
        code_blocks.append(match.group(0))
        return f"__CODE_BLOCK_{len(code_blocks) - 1}__"
    safe_text = re.sub(r"```.*?\n.*?```", replacer, text, flags=re.DOTALL)
    return safe_text, code_blocks

def restore_code_blocks(text: str, code_blocks: List[str]) -> str:
    for i, block in enumerate(code_blocks):
        text = text.replace(f"__CODE_BLOCK_{i}__", block)
    return text

def split_markdown_by_heading(text: str, max_chars_per_chunk: int = 3000) -> List[str]:
    safe_text, code_blocks = extract_code_blocks(text)
    headings = list(re.finditer(r'^(#{1,6}\s+.*)', safe_text, re.MULTILINE))
    
    sections = []
    for i, match in enumerate(headings):
        start = match.start()
        end = headings[i + 1].start() if i + 1 < len(headings) else len(safe_text)
        sections.append(safe_text[start:end].strip())

    chunks, current_chunk = [], ""
    for section in sections:
        if len(current_chunk) + len(section) < max_chars_per_chunk:
            current_chunk += section + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = section + "\n\n"
    if current_chunk:
        chunks.append(current_chunk.strip())

    return [restore_code_blocks(chunk, code_blocks) for chunk in chunks]

def run_llm_process(chunks: List[str], prompt_template, llm) -> List[str]:
    results = []
    for i, chunk in enumerate(tqdm(chunks, desc="ğŸ§¹ Processing Chunks", leave=False)):
        try:
            prompt = prompt_template.format(context_str=chunk)
            response = llm.complete(prompt)
            results.append(response.text.strip())
        except Exception as e:
            logging.error(f"[Chunk {i+1}] å¤„ç†å¤±è´¥: {e}")
            results.append(f"<!-- å¤„ç†å¤±è´¥ï¼š{e} -->\n{chunk}\n<!-- ç»“æŸå¤„ç†å¤±è´¥-ç»“æŸ -->")
    return results

def write_debug_chunks(original_chunks, processed_chunks, rel_path: str, output_dir: str = DEBUG_CLEAN_DIR):
    """
    å°†åŸå§‹å’Œå¤„ç†åçš„ Markdown æ–‡æœ¬å—å†™å…¥æŒ‡å®šç›®å½•ã€‚
    
    :param original_chunks: åŸå§‹çš„ Markdown æ–‡æœ¬å—åˆ—è¡¨
    :param processed_chunks: å¤„ç†åçš„ Markdown æ–‡æœ¬å—åˆ—è¡¨
    :param rel_path: ç›¸å¯¹è·¯å¾„ï¼Œç”¨äºç”Ÿæˆè¾“å‡ºæ–‡ä»¶çš„è·¯å¾„
    :param output_dir: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„ï¼Œé»˜è®¤ä¸º DEBUG_CLEAN_DIR
    :raises ValueError: å¦‚æœè¾“å…¥å‚æ•°æ— æ•ˆ
    :raises IOError: å¦‚æœæ–‡ä»¶å†™å…¥å¤±è´¥
    """
    if not original_chunks or not processed_chunks:
        raise ValueError("åŸå§‹åˆ‡ç‰‡æˆ–å¤„ç†ååˆ‡ç‰‡ä¸èƒ½ä¸ºç©º")
    if len(original_chunks) != len(processed_chunks):
        raise ValueError("åŸå§‹åˆ‡ç‰‡å’Œå¤„ç†ååˆ‡ç‰‡æ•°é‡ä¸åŒ¹é…")

    sep = "\n" + "=" * 100 + "\n"
    try:
        rel_md_path = Path(rel_path).with_suffix(".md")
        if not rel_md_path.name:  # æ£€æŸ¥æ–‡ä»¶åæœ‰æ•ˆæ€§
            raise ValueError("æ— æ•ˆçš„ç›¸å¯¹è·¯å¾„")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir_path = Path(output_dir)
        output_dir_path.mkdir(parents=True, exist_ok=True)

        # åŸå§‹åˆ‡ç‰‡è·¯å¾„ - ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­æ€§å†™å…¥
        input_path = output_dir_path / ("input_" + rel_md_path.name)
        temp_input_path = input_path.with_suffix(".tmp")
        temp_input_path.write_text(sep.join(original_chunks), encoding="utf-8")
        temp_input_path.replace(input_path)

        # å¤„ç†ååˆ‡ç‰‡è·¯å¾„ - ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ç¡®ä¿åŸå­æ€§å†™å…¥
        output_path = output_dir_path / ("processed_" + rel_md_path.name)
        temp_output_path = output_path.with_suffix(".tmp")
        temp_output_path.write_text(sep.join(processed_chunks), encoding="utf-8")
        temp_output_path.replace(output_path)

    except Exception as e:
        logging.error(f"å†™å…¥è°ƒè¯•æ–‡ä»¶å¤±è´¥: {e}")
        raise IOError(f"æ— æ³•å†™å…¥è°ƒè¯•æ–‡ä»¶: {e}")
