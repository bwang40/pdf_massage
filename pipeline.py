# pipeline.py
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from typing import Callable, Optional
import logging
import shutil

from pdf_processing.mineru_converter import convert_pdf_to_markdown
from pdf_processing.file_extractor import extract_auto_contents
from markdown_processing.cleaner import clean_md
from markdown_processing.translator import translate_md
from config import (
    EXTRACTED_DIR,
    CLEANED_DIR,
    TRANSLATED_DIR,
    ORIGIN_DIR,
    DEBUG,
)

from api_key import LLM_API_KEY  # Ensure this is imported correctly
from llama_index.core import Settings
from llama_index.llms.deepseek import DeepSeek

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

def copy_non_markdown_files(input_dir: Path, output_dir: Path) -> None:
    """é€’å½’åœ°å¤åˆ¶éMarkdownæ–‡ä»¶å’Œæ–‡ä»¶å¤¹"""
    for item in input_dir.iterdir():
        dst = output_dir / item.name
        if item.is_dir():
            print(f"å¤åˆ¶æ–‡ä»¶å¤¹: {item}")
            dst.mkdir(parents=True, exist_ok=True)  # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
            copy_non_markdown_files(item, dst)  # é€’å½’å¤„ç†å­æ–‡ä»¶å¤¹
        elif item.suffix.lower() != ".md":
            print(f"å¤åˆ¶æ–‡ä»¶: {item}")
            shutil.copy2(item, dst)  # å¤åˆ¶éMarkdownæ–‡ä»¶

def process_files(
    input_dir: Path,
    output_dir: Path,
    process_func: Callable[[str, str, Optional[DeepSeek], bool], None],
    llm: Optional[DeepSeek] = None,
    debug: bool = False,
    parallel: bool = False
) -> None:
    """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰Markdownæ–‡ä»¶å¹¶å¤åˆ¶éMarkdownæ–‡ä»¶å¤¹"""
    # å¤åˆ¶æ‰€æœ‰éMarkdownæ–‡ä»¶å¤¹
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å¤åˆ¶æ‰€æœ‰é Markdown æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
    copy_non_markdown_files(input_dir, output_dir)
    
    # å¤„ç†Markdownæ–‡ä»¶
    files = list(input_dir.rglob("*.md"))
    if not files:
        logger.warning(f"åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°Markdownæ–‡ä»¶")
        return

    def process_file(file_path: Path) -> None:
        try:
            output_path = output_dir / file_path.relative_to(input_dir)
            process_func(str(file_path), str(output_path), llm, debug)
            logger.info(f"æˆåŠŸå¤„ç†: {file_path}")
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} å¤±è´¥: {e}")

    if parallel:
        with ThreadPoolExecutor() as executor:
            executor.map(process_file, files)
    else:
        for file_path in files:
            process_file(file_path)

def run_pipeline(pdf_path: str) -> None:
    try:
        # åˆå§‹åŒ–LLM
        Settings.llm = DeepSeek(model="deepseek-chat", api_key=LLM_API_KEY)

        logger.info("ğŸš€ å¼€å§‹PDFå¤„ç†æµç¨‹")

        # Step 1: PDF è½¬æ¢ä¸º Markdown
        logger.info("ğŸ“„ è½¬æ¢PDFä¸ºMarkdown")
        convert_pdf_to_markdown(pdf_path=pdf_path, output_dir=ORIGIN_DIR)

        # Step 2: æå–Markdownå’Œå›¾åƒæ–‡ä»¶
        logger.info("ğŸ” æå–Markdownå†…å®¹")
        extract_auto_contents(ORIGIN_DIR, EXTRACTED_DIR)

        # Step 3: æ¸…æ´—Markdownæ–‡ä»¶
        logger.info("ğŸ§¹ æ¸…æ´—Markdownæ–‡ä»¶")
        process_files(
            Path(EXTRACTED_DIR),
            Path(CLEANED_DIR),
            clean_md,
            llm=Settings.llm,
            debug=DEBUG,
        )

        # Step 4: ç¿»è¯‘Markdownæ–‡ä»¶
        logger.info("ğŸŒ ç¿»è¯‘Markdownæ–‡ä»¶")
        process_files(
            Path(CLEANED_DIR),
            Path(TRANSLATED_DIR),
            translate_md,
            llm=Settings.llm,
            debug=DEBUG,
        )

        logger.info("âœ… å¤„ç†å®Œæˆ")
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    from config import PDF_PATH

    run_pipeline(PDF_PATH)
