{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775add4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# 原始 PDF 文件路径\n",
    "pdf_path = r\"D:\\workspace\\pdf_convert_clean_trans\\input\\ISO 26262-1-2018.pdf\"\n",
    "\n",
    "# 获取文件名并替换字符\n",
    "filename = os.path.basename(pdf_path)\n",
    "new_filename = filename.replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "new_pdf_path = os.path.join(os.getcwd(), \".tmp\", new_filename)\n",
    "\n",
    "# 创建 .tmp 文件夹\n",
    "tmp_dir = os.path.dirname(new_pdf_path)\n",
    "\n",
    "# 将原始 PDF 文件复制到 .tmp 文件夹\n",
    "shutil.copy(pdf_path, new_pdf_path)\n",
    "\n",
    "os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "# 构造输出目录\n",
    "output_dir = os.path.join(tmp_dir, \"origin\")\n",
    "\n",
    "# 创建 origin 子文件夹\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 调用 mineru 命令行工具进行 PDF 转换\n",
    "result = subprocess.run(\n",
    "    [\"mineru\", \"-p\", new_pdf_path, \"-o\", output_dir],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# 检查命令执行结果\n",
    "if result.returncode == 0:\n",
    "    print(\"命令执行成功\")\n",
    "    print(\"输出：\", result.stdout)\n",
    "else:\n",
    "    print(\"命令执行失败\")\n",
    "    print(\"错误：\", result.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a1c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有内容提取并重命名完成\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INPUT_DIR = \"./.tmp/origin\"\n",
    "EXTRACTED_DIR = \"./.tmp/extracted_origin\"\n",
    "\n",
    "def sanitize_name(name: str) -> str:\n",
    "    \"\"\"统一替换名称中的空格为下划线\"\"\"\n",
    "    return name.replace(\" \", \"_\")\n",
    "\n",
    "def extract_auto_contents(input_dir: str, output_dir: str):\n",
    "    input_path = Path(input_dir)\n",
    "\n",
    "    for sub_dir in input_path.iterdir():\n",
    "        if not sub_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        auto_path = sub_dir / \"auto\"\n",
    "        if not auto_path.exists():\n",
    "            continue\n",
    "\n",
    "        # 替换子文件夹名中的空格\n",
    "        sanitized_subdir_name = sanitize_name(sub_dir.name)\n",
    "        target_subdir = os.path.join(output_dir, sanitized_subdir_name)\n",
    "        os.makedirs(target_subdir, exist_ok=True)\n",
    "\n",
    "        # 拷贝 auto 下的 Markdown 文件（*.md）\n",
    "        for md_file in auto_path.glob(\"*.md\"):\n",
    "            if md_file.is_file():\n",
    "                sanitized_filename = sanitize_name(md_file.name)\n",
    "                shutil.copy2(md_file, os.path.join(target_subdir, sanitized_filename))\n",
    "\n",
    "        # 拷贝 auto/images 目录下的所有文件\n",
    "        image_dir = auto_path / \"images\"\n",
    "        if image_dir.exists() and image_dir.is_dir():\n",
    "            target_image_dir = os.path.join(target_subdir, \"images\")\n",
    "            os.makedirs(target_image_dir, exist_ok=True)\n",
    "\n",
    "            for img_file in image_dir.rglob(\"*.*\"):\n",
    "                if img_file.is_file():\n",
    "                    sanitized_img_name = sanitize_name(img_file.name)\n",
    "                    shutil.copy2(img_file, os.path.join(target_image_dir, sanitized_img_name))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extract_auto_contents(INPUT_DIR, EXTRACTED_DIR)\n",
    "    print(\"✅ 所有内容提取并重命名完成\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957aac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from llama_index.core.utils import count_tokens\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.deepseek import DeepSeek\n",
    "from llama_index.embeddings.openai_like import OpenAILikeEmbedding\n",
    "\n",
    "# ========== 配置部分 ==========\n",
    "EXTRACTED_DIR = \"./.tmp/extracted_origin\"\n",
    "CLEANED_DIR = \"./.tmp/cleaned\"\n",
    "TRANS_DIR = \"./.tmp/translated\"\n",
    "DEBUG = True\n",
    "\n",
    "DEBUG_CLEAN_DIR = \"./.tmp/debug_clean_chunk\"\n",
    "DEBUG_TRANS_DIR = \"./.tmp/debug_trans_chunk\"\n",
    "\n",
    "MAX_TOKENS_PER_CHUNK = 6000\n",
    "\n",
    "# 日志配置\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"errors.log\", encoding=\"utf-8\")]\n",
    ")\n",
    "\n",
    "# LLM 配置\n",
    "Settings.llm = DeepSeek(model=\"deepseek-chat\", api_key=\"sk-eac019be79f14f948591d963d8c17656\")\n",
    "Settings.embed_model = OpenAILikeEmbedding(\n",
    "    model_name=\"text-embedding-v4\",\n",
    "    api_base=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    "    api_key=\"sk-e9aeb7dc9a3e4bf784411b295ddfa402\",\n",
    "    embed_batch_size=10,\n",
    ")\n",
    "Settings.chunk_size = 512\n",
    "Settings.chunk_overlap = 64\n",
    "\n",
    "# Prompt 模板\n",
    "clean_prompt = PromptTemplate(r\"\"\"\n",
    "你是一个专业的 Markdown 格式修复专家。你将接收由 OCR 或 PDF 转换工具（如 Mineru）生成的 Markdown 文件，该文件格式存在严重错误，请你对其进行以下修复，保持语义和结构不变，仅修复格式问题。\n",
    "\n",
    "请严格遵守以下规则：\n",
    "\n",
    "1. **修复标题格式：**\n",
    "   - 所有形如 `# N` 的标题为一级标题（例如 `# 1`、`# 2`）；\n",
    "   - 所有形如 `N.N` 的应为二级标题 `## N.N`；\n",
    "   - 所有形如 `N.N.N` 的为三级标题 `### N.N.N`；\n",
    "   - 如果标题前存在错误的 `#` 个数（如 `### 3.3` 应是 `## 3.3`），请纠正。\n",
    "\n",
    "2. **修复列表格式：**\n",
    "   - 所有以 `—` 或 `–`、长破折号或错误符号开头的条目，应统一为 `-`（标准 Markdown 无序列表）；\n",
    "   - 若嵌套列表存在缩进错误，按照 2 个空格作为每一级缩进进行规范；\n",
    "   - 若多级列表中存在自然语言段落描述，请确保子项缩进正确，并在每项后加换行。\n",
    "\n",
    "3. **修复 NOTE 标注：**\n",
    "   - 将类似“Note 1 to entry: …” 转换为以下标准格式：\n",
    "     ```markdown\n",
    "     > [!NOTE]\n",
    "     > Note 1 to entry: ...\n",
    "     ```\n",
    "   - 同一段中多个 Note，依次编号，保持缩进一致。\n",
    "\n",
    "4. **修复数学公式污染：**\n",
    "   - 若出现 LaTeX 数学语法未正确渲染，例如：\n",
    "     ```markdown\n",
    "     $\" \\mathrm { m } { \\cdot } \\mathrm { n } ^ { \\prime \\prime }$ \n",
    "     ```\n",
    "     应尽量转换为正常文本（如 `m·n″`），或保留为行内公式 `\\( m \\cdot n^{\\prime\\prime} \\)`。\n",
    "\n",
    "5. **修复乱码和不必要符号：**\n",
    "   - 删除无效转义符（如 `\\`、`\\``, `\\`, `,` 等成对混乱出现的标点）；\n",
    "   - 修复 markdown 中图像语法错误（如 `![]()`）中路径丢失或注释混乱的问题；\n",
    "   - 删除重复空格和空行，确保段落之间最多保留一个空行。\n",
    "\n",
    "6. **保持内容原始语义不变**，仅做格式清洗。\n",
    "\n",
    "输出格式为**修复后的完整 Markdown 文件**。不要进行额外解释或注释。\n",
    "\n",
    "请清洗以下 Markdown 文本：\n",
    "\n",
    "{context_str}\n",
    "\"\"\")\n",
    "\n",
    "translation_prompt = PromptTemplate(r\"\"\"\n",
    "你是一个专业的 Markdown 文档翻译机器人，负责将英文 Markdown 文档翻译为自然、准确的中文。你收到的 Markdown 文档可能是经过切分的片段，结构可能不完整，存在缺少一级标题、从中间段落开始或标题层级不规范等情况。请严格保留原文 Markdown 格式，不得更改标题层级或破坏任何结构性语法。\n",
    "\n",
    "请遵循以下翻译规则：\n",
    "\n",
    "1. **严格保留所有 Markdown 结构和语法**，包括但不限于标题（如 `#` `##` `###` `####` 等）、列表（有序/无序）、链接、图片、代码块、表格、引用、分隔线等，不得增删或调整层级；\n",
    "2. **所有标题符号必须严格保留，标题等级不可更改**；\n",
    "3. **所有代码块（```）和行内代码（`code`）必须完整保留，禁止翻译或更动任何字符**；\n",
    "4. **图片和链接中的 URL、文件名、路径等保持原样，不得翻译或修改**；\n",
    "5. 正文内容应翻译为专业、通顺、自然的中文；\n",
    "6. **仅输出翻译后的中文 Markdown 内容**；\n",
    "7. 即使输入被切分为不完整段落，也**不得破坏原有 Markdown 的结构**；\n",
    "\n",
    "请翻译以下 Markdown 文本：\n",
    "\n",
    "{context_str}\n",
    "\"\"\")\n",
    "\n",
    "# ========== 工具函数 ==========\n",
    "def extract_code_blocks(text: str) -> Tuple[str, List[str]]:\n",
    "    code_blocks = []\n",
    "    def replacer(match):\n",
    "        code_blocks.append(match.group(0))\n",
    "        return f\"__CODE_BLOCK_{len(code_blocks) - 1}__\"\n",
    "    safe_text = re.sub(r\"```.*?\\n.*?```\", replacer, text, flags=re.DOTALL)\n",
    "    return safe_text, code_blocks\n",
    "\n",
    "def restore_code_blocks(text: str, code_blocks: List[str]) -> str:\n",
    "    for i, block in enumerate(code_blocks):\n",
    "        text = text.replace(f\"__CODE_BLOCK_{i}__\", block)\n",
    "    return text\n",
    "\n",
    "def split_markdown_by_heading(text: str, max_chars_per_chunk: int = 3000) -> List[str]:\n",
    "    safe_text, code_blocks = extract_code_blocks(text)\n",
    "    headings = list(re.finditer(r'^(#{1,6}\\s+.*)', safe_text, re.MULTILINE))\n",
    "    \n",
    "    sections = []\n",
    "    for i, match in enumerate(headings):\n",
    "        start = match.start()\n",
    "        end = headings[i + 1].start() if i + 1 < len(headings) else len(safe_text)\n",
    "        sections.append(safe_text[start:end].strip())\n",
    "\n",
    "    chunks, current_chunk = [], \"\"\n",
    "    for section in sections:\n",
    "        if len(current_chunk) + len(section) < max_chars_per_chunk:\n",
    "            current_chunk += section + \"\\n\\n\"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = section + \"\\n\\n\"\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return [restore_code_blocks(chunk, code_blocks) for chunk in chunks]\n",
    "\n",
    "def run_cleaning(chunks: List[str], prompt_template, llm) -> List[str]:\n",
    "    results = []\n",
    "    for i, chunk in enumerate(tqdm(chunks, desc=\"🧹 Cleaning Chunks\", leave=False)):\n",
    "        try:\n",
    "            prompt = prompt_template.format(context_str=chunk)\n",
    "            response = llm.complete(prompt)\n",
    "            results.append(response.text.strip())\n",
    "        except Exception as e:\n",
    "            logging.error(f\"[Chunk {i+1}] 清洗失败: {e}\")\n",
    "            results.append(f\"<!-- 清洗失败：{e} -->\")\n",
    "    return results\n",
    "\n",
    "def write_debug_chunks(original_chunks, processed_chunks, rel_path: str):\n",
    "    sep = \"\\n\" + \"=\" * 100 + \"\\n\"\n",
    "    rel_md_path = Path(rel_path).with_suffix(\".md\")\n",
    "\n",
    "    # 原始切片\n",
    "    input_path = Path(DEBUG_CLEAN_DIR) / (\"input_\"+rel_md_path)\n",
    "    input_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    input_path.write_text(sep.join(original_chunks), encoding=\"utf-8\")\n",
    "\n",
    "    # 处理后切片\n",
    "    output_path = Path(DEBUG_CLEAN_DIR) / (\"processed_\"+rel_md_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    output_path.write_text(sep.join(processed_chunks), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "def clean_md(input_path: str, output_path: str, debug: bool = False,\n",
    "             prompt_template=None, llm=None, input_dir=None, debug_input_dir=None, \n",
    "             debug_output_dir=None, max_tokens=6000):\n",
    "    text = Path(input_path).read_text(encoding=\"utf-8\")\n",
    "    chunks = split_markdown_by_heading(text, max_chars_per_chunk=max_tokens)\n",
    "    results = run_cleaning(chunks, prompt_template, llm)\n",
    "    Path(output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    Path(output_path).write_text(\"\\n\\n\".join(results), encoding=\"utf-8\")\n",
    "\n",
    "    if debug:\n",
    "        rel_path = os.path.relpath(input_path, input_dir)\n",
    "        write_debug_chunks(chunks, results, rel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d640842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def idisplay_markdown(markdown_text: str):\n",
    "    \"\"\"在 Jupyter 中渲染显示 Markdown 内容\"\"\"\n",
    "    display(Markdown(markdown_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f2649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55c836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15edf9f1bf74298a6568bf0c9c09974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🧹 Cleaning Files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d26cc048ce4d4f9d473ac4a2a12b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "🧹 Cleaning Chunks:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files = list(Path(EXTRACTED_DIR).rglob(\"*.*\"))\n",
    "\n",
    "for file_path in tqdm(files, desc=\"🧹 Cleaning Files\"):\n",
    "    rel_path = os.path.relpath(file_path, EXTRACTED_DIR)\n",
    "    output_path = os.path.join(CLEANED_DIR, rel_path)\n",
    "\n",
    "    try:\n",
    "        if file_path.suffix.lower() in [\".md\", \".mdx\"]:\n",
    "            clean_md(\n",
    "                input_path=str(file_path),\n",
    "                output_path=output_path,\n",
    "                debug=DEBUG,\n",
    "                prompt_template=clean_prompt,\n",
    "                llm=Settings.llm,\n",
    "                input_dir=EXTRACTED_DIR,\n",
    "                debug_input_dir=DEBUG_CLEAN_DIR,\n",
    "                debug_output_dir=DEBUG_CLEAN_DIR,\n",
    "                max_tokens=MAX_TOKENS_PER_CHUNK\n",
    "            )\n",
    "        else:\n",
    "            shutil.copyfile(file_path, output_path)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[{rel_path}] 文件清洗失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686d83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95008090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a766c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
